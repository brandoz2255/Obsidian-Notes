# OG thoughts 

- The original concept of this project 

# Phase one
- Looks at and describes what its looking at via camera
- then waits for my gestures to do a pre-programmed tasks
- first volume up and down the volume with my fingers 
- second open obsidian, firefox,Terminal 
- third type with just gestures (might do this but sounds kinda cool)
- Analyze more than just people!! 
- Facial recognition  for sudo commands 
- GUI 

## What its evolved to

Might just make it as intended however this was just research for me to get an idea of how computer vision worked and how I can play around with it 

- Learned that I can do it without QT gui from python the issue was on my machine I use hyprland desktop
	- Hyprland isn't compatible with QT so the idea evolved with using Electron for the GUI 
		- now it evolved to both a web browser GUI and electron however the electron based part comes first and its only the front end
		- We are going to switch for the backend research and developement be using Tkinter and PysimpleGUI 
			- If this still doesn't work in hyprland I would need to move my project operation onto that machine and state in the README/requirements.txt that its incompatible with hyprland